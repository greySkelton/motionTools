# read.R

# silence readr messages
options(readr.num_columns = 0)

# Be sure to add your own token

#' Read data from a REDCap report. Default arguments depend on specific project.
#' @importFrom magrittr %>%
#' @export
ReadRedcapReport = function(
  token = GetRedcapToken(),
  url = "https://redcap.emory.edu/api/",
  report_id = '29228'
){
  form.data <- list("token"=token,
                    content='report',
                    format='csv',
                    report_id=report_id,
                    csvDelimiter='',
                    rawOrLabel='raw',
                    rawOrLabelHeaders='raw',
                    exportCheckboxLabel='false',
                    returnFormat='json'
  )
  response <- httr::POST(url, body = form.data, encode = "form")
  httr::content(response)
}

#' Read data from REDCap and restructure
#' @importFrom magrittr %>%
#' @export
ReadRedcap = function() ReadRedcapReport() %>%
  dplyr::mutate(gender = if_else(sex==1,"Female","Male")) %>%
  dplyr::select(-sex) %>%
  rename(age = age_capture) %>%
  dplyr::mutate(diagnosis = if_else(dw_primary_diagnosis %in% c("Paralysis agitans","Parkinson's disease"),"Parkinson's disease",
                                    if_else(dw_primary_diagnosis %in% c("Essential tremor","Essential and other specified forms of tremor"),"Essential Tremor","Other"))) %>%
  dplyr::mutate(diagnosis = factor(diagnosis,levels = c("Parkinson's disease","Essential Tremor","Other")))

#' Return personal.dat file based on NRM file location
#' @importFrom magrittr %>%
#' @export
FindPersonalData = function(nrm.file){
  f = file.path(dirname(nrm.file),"personal.dat")
  if(!file.exists(f)){f = ""}
  f
}

# Read subject data (height, weight, MRN) from personal.dat files generated by Orthotrack
#' @importFrom magrittr %>%
#' @export
ReadPersonalData = function(file.name) read_delim(file.name, delim = ":", col_names = F, n_max = 16) %>% pivot_wider(names_from="X1",values_from="X2")

# Read the estimated joint centers from the .trbcoord files.
#' @importFrom magrittr %>%
#' @export
ReadTrbCoord = function(file.name){
  t = read_tsv(file.name)
  n = names(t)
  outcome.names.x = n[seq(3,length(n),3)] %>% str_replace_all("  X",".X") %>% str_remove_all(" ") %>% str_replace_all("/",".")
  outcome.names.y = outcome.names.x %>% str_replace(".X$",".Y")
  outcome.names.z = outcome.names.x %>% str_replace(".X$",".Z")
  names(t) = c(n[1:2],rbind(outcome.names.x,outcome.names.y,outcome.names.z) %>% c())
  t = t %>% pivot_longer(-c(Frame,`Time(sec)`),names_to = "Landmark", values_to="Position") %>%
    dplyr::arrange(Landmark,Frame) %>%
    dplyr::mutate(Coordinate = str_sub(Landmark, start= -1)) %>%
    dplyr::mutate(Landmark = str_sub(Landmark, end = -3))
  t %>% rename(frame_num = Frame, time_sec = `Time(sec)`, variable = Landmark, value = Position, coordinate = Coordinate)
  t
}

# Read the average data from the nrm file. note that in some cases a large number of empty columns are generated; only extract the first three.
#' @export
ReadNrmAverages = function(nrm_file) read_tsv(nrm_file,n_max=27,col_types = cols(Side = "c", Right = "d", Left = "d"))[,1:3] %>% 
rename(Variable = Side, lft = Left, rt = Right) %>%
  pivot_longer(-Variable, names_to = "Side", values_to = "Value") %>%
  left_join(
    tibble(
      Variable = c(
        "Step Length  Avg (cm)",
        "Number of Steps",
        "Stride Length Avg (cm)",
        "Number of Strides",
        "Forward Velocity Avg (cm/s)",
        "Cadence Avg (steps/min)",
        "Total  Support Time (%)",
        "Swing Phase (%)",
        "Initial Double Support Time (%)",
        "Single Support Time (%)",
        "Step Width (cm)"
      ),
      new.name = c(
        "step_leng_ave",
        "num_steps",
        "strid_leng_ave",
        "num_strides",
        "for_vel",
        "cad_ave",
        "tot_sup_time",
        "swing_phas",
        "int_2x_sup_time",
        "single_sup_time",
        "step_width"
      )
    )) %>%
  na.exclude() %>%
  mutate(Variable = paste(new.name,Side,sep="_")) %>%
  select(-c(new.name,Side)) %>%
  unique() %>%
  group_by(Variable) %>%
  summarize(Value = min(Value, na.rm=T)) %>%
  ungroup() %>%
  pivot_wider(names_from="Variable",values_from="Value") %>%
  rename(step_width = step_width_rt) %>% select(-step_width_lft) %>% 
  select(
    step_leng_ave_rt,
    step_leng_ave_lft,
    strid_leng_ave_rt,
    strid_leng_ave_lft,
    for_vel_rt,
    for_vel_lft,
    cad_ave_rt,
    cad_ave_lft,
    tot_sup_time_rt,
    tot_sup_time_lft,
    swing_phas_rt,
    swing_phas_lft,
    int_2x_sup_time_rt,
    int_2x_sup_time_lft,
    single_sup_time_rt,
    single_sup_time_lft,
    step_width,
    num_steps_rt,
    num_steps_lft,
    num_strides_rt,
    num_strides_lft)


# Read the timeseries data from the nrm file. this produces raw data of 100x46 doubles.
# to scale, you should add to database. to get done, you should do in memory.
# keeping the kinematic marker data will definitely need a database.
#' @importFrom magrittr %>%
#' @export
ReadNrmTimeseries = function(nrm_file){
  raw = read_tsv(nrm_file,skip=28) %>% select(-starts_with("SD"))
  raw[,1:46] %>%
    dplyr::mutate(percent_gait_cycle = row_number()) %>%
    select(percent_gait_cycle, everything())
}

# read anthropemetric data from personal.dat.
#' @importFrom magrittr %>%
#' @export
ReadPersonalData = function(file.name) read_delim(file.name, delim = ":", col_names = F, n_max = 16) %>%
  pivot_wider(names_from="X1",values_from="X2") %>%
  select(-ends_with("Name")) %>%
  select(-ends_with("Date")) %>% 
  select(-ends_with("ID#")) %>% 
  FixNames() %>% 
  mutate(across(-marker.set,as.numeric))

# Read single row of a .trc file
#' @export
ReadTrcRow = function(file.name, skip = 0) read.delim(file.name, skip = skip, nrows = 1, header = F)

# Read trc file header.
# Note that on read-in, backslashes in filenames are rendered as "\\" this is the backslash character in r, no need to attempt to remove.
#' @export
ReadTrcHeader = function(file.name){
  source.file = ReadTrcRow(file.name,0)[4]
  names(source.file) = "SourceFile"
  parameter.names = ReadTrcRow(file.name,1)
  parameters = ReadTrcRow(file.name,2)
  names(parameters) = parameter.names
  dplyr::bind_cols(source.file,parameters)
}

# Read in the first 60 (or n.markers) variable names.
#' @importFrom magrittr %>%
#' @export
ReadTrcVariableNames = function(file.name, n.markers = 60){
  # the first two columns are frame number and time
  n.cols = n.markers*3 + 2
  variable.stubs = as.character(zoo::na.locf(t(read.delim(file.name, skip = 3, nrows = 1, header = F)[1:n.cols])))
  variable.coordinates = as.character(t(read.delim(file.name, skip = 4, nrows = 1, header = F)[1:n.cols]) %>% stringr::str_extract("[XYZ]"))
  variable.names = character(length = length(variable.stubs))
  for(i in 1:length(variable.names)){
    if(i>2){
      variable.names[i] = paste0(variable.stubs[i],".",variable.coordinates[i])
    }else{variable.names[i] = variable.stubs[i]}
  }
  variable.names[variable.names=="Frame#"] = "Frame"
  return(variable.names)
}

# Read in the first 60 (or n.markers) columns of data from a .trc file.
#' @importFrom magrittr %>%
#' @export
ReadTrcData = function(file.name, n.markers = 60){
  n.cols = n.markers*3 + 2
  variable.names = ReadTrcVariableNames(file.name, n.markers)
  numeric.data = read.delim(file.name,skip=6,header=F)[,1:n.cols]
  names(numeric.data) = variable.names
  trc.data = tidyr::as_tibble(numeric.data)
}



